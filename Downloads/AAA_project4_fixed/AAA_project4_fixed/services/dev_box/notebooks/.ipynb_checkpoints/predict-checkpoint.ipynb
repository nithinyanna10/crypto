{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737818d7-e9c0-4a4f-a814-bc480b506407",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/models/metrics.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 230\u001b[39m\n\u001b[32m    226\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrediction saved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minterval_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | signal=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msignal\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | proba=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproba\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    229\u001b[39m     \u001b[38;5;66;03m# * * * * * sleep 15; /usr/bin/python3 /path/to/predict.py\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[43mpredict_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 159\u001b[39m, in \u001b[36mpredict_and_save\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# 1. Load model and feature params\u001b[39;00m\n\u001b[32m    158\u001b[39m model = joblib.load(model_path)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmetrics_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    160\u001b[39m     best_params = json.load(f)[\u001b[33m'\u001b[39m\u001b[33mbest_params\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# 2. Fetch last 30 days of candles\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/data/models/metrics.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# --- Feature engineering function (must match training) ---\n",
    "def generate_features(\n",
    "    candles,\n",
    "    rolling_volatility_window=30,\n",
    "    trix_period=30,\n",
    "    tema_period=30,\n",
    "    bbands_period=20,\n",
    "    macd_fast=12,\n",
    "    macd_slow=26,\n",
    "    obv_window=30,\n",
    "    ewma_span=10,\n",
    "    predict_horizon_minutes=5\n",
    "):\n",
    "    candles = candles.copy()\n",
    "    candles['interval_start'] = pd.to_datetime(candles['interval_start'])\n",
    "    candles['interval_end'] = pd.to_datetime(candles['interval_end'])\n",
    "    candles['future_close'] = candles['close_price'].shift(-predict_horizon_minutes)\n",
    "    candles['target_return'] = (candles['future_close'] - candles['close_price']) / candles['close_price']\n",
    "    candles['signal'] = (candles['target_return'] > 0).astype(int)\n",
    "\n",
    "    candles['rolling_volatility'] = candles['close_price'].rolling(window=rolling_volatility_window).std()\n",
    "    candles['volume_spike'] = candles['volume'] / candles['volume'].rolling(window=rolling_volatility_window).mean()\n",
    "    candles['minute_of_day'] = candles['interval_start'].dt.hour * 60 + candles['interval_start'].dt.minute\n",
    "    candles['momentum_5'] = candles['close_price'].pct_change(5)\n",
    "    candles['momentum_15'] = candles['close_price'].pct_change(15)\n",
    "    candles['range_ratio'] = (candles['high_price'] - candles['low_price']) / candles['close_price']\n",
    "    candles['slope_10'] = candles['close_price'].diff(10) / 10\n",
    "    candles['day_of_week'] = candles['interval_start'].dt.dayofweek\n",
    "    candles['hour_sin'] = np.sin(2 * np.pi * candles['interval_start'].dt.hour / 24)\n",
    "    candles['hour_cos'] = np.cos(2 * np.pi * candles['interval_start'].dt.hour / 24)\n",
    "\n",
    "    us_market_open = 13\n",
    "    asia_market_open = 1\n",
    "    europe_market_open = 7\n",
    "\n",
    "    def minutes_from_market(hour, minute, market_hour):\n",
    "        mins = hour * 60 + minute\n",
    "        delta = mins - market_hour * 60\n",
    "        if delta < 0:\n",
    "            delta += 1440\n",
    "        return delta\n",
    "\n",
    "    candles['minutes_from_us_open'] = candles['interval_start'].apply(lambda x: minutes_from_market(x.hour, x.minute, us_market_open))\n",
    "    candles['minutes_from_asia_open'] = candles['interval_start'].apply(lambda x: minutes_from_market(x.hour, x.minute, asia_market_open))\n",
    "    candles['minutes_from_europe_open'] = candles['interval_start'].apply(lambda x: minutes_from_market(x.hour, x.minute, europe_market_open))\n",
    "\n",
    "    for market in ['us', 'asia', 'europe']:\n",
    "        candles[f'norm_{market}_time'] = candles[f'minutes_from_{market}_open'] / 1440\n",
    "        candles[f'{market}_time_sin'] = np.sin(2 * np.pi * candles[f'norm_{market}_time'])\n",
    "        candles[f'{market}_time_cos'] = np.cos(2 * np.pi * candles[f'norm_{market}_time'])\n",
    "\n",
    "    import talib\n",
    "    candles['trix'] = talib.TRIX(candles['close_price'].values, timeperiod=trix_period)\n",
    "    candles['tema'] = talib.TEMA(candles['close_price'].values, timeperiod=tema_period)\n",
    "    candles['dx'] = talib.DX(candles['high_price'].values, candles['low_price'].values, candles['close_price'].values)\n",
    "    candles['sar'] = talib.SAR(candles['high_price'].values, candles['low_price'].values)\n",
    "    candles['atr'] = talib.ATR(candles['high_price'].values, candles['low_price'].values, candles['close_price'].values)\n",
    "    candles['volume_ema'] = candles['volume'].ewm(span=20).mean()\n",
    "    candles['volume_ratio'] = candles['volume'] / candles['volume_ema']\n",
    "    candles['volume_oscillator'] = (candles['volume'].rolling(window=5).mean() / candles['volume'].rolling(window=20).mean() - 1) * 100\n",
    "\n",
    "    candles['vwap_daily'] = 0.0\n",
    "    for date in candles['interval_start'].dt.date.unique():\n",
    "        mask = candles['interval_start'].dt.date == date\n",
    "        if mask.any():\n",
    "            candles.loc[mask, 'vwap_daily'] = (candles.loc[mask, 'volume'] * candles.loc[mask, 'close_price']).cumsum() / candles.loc[mask, 'volume'].cumsum()\n",
    "    candles['vwap_ratio'] = candles['close_price'] / candles['vwap_daily'].replace(0, np.nan)\n",
    "\n",
    "    candles['adx'] = talib.ADX(candles['high_price'].values, candles['low_price'].values, candles['close_price'].values)\n",
    "    candles['adx_strong'] = (candles['adx'] > 25).astype(int)\n",
    "    candles['obv'] = talib.OBV(candles['close_price'].values, candles['volume'].values)\n",
    "    candles['obv_rolling'] = candles['obv'].rolling(window=obv_window).mean()\n",
    "    candles['willr'] = talib.WILLR(candles['high_price'].values, candles['low_price'].values, candles['close_price'].values)\n",
    "    candles['mfi'] = talib.MFI(candles['high_price'].values, candles['low_price'].values, candles['close_price'].values, candles['volume'].values)\n",
    "    candles['rsi'] = talib.RSI(candles['close_price'].values)\n",
    "\n",
    "    # EWMA features\n",
    "    candles['ewma_close'] = candles['close_price'].ewm(span=ewma_span).mean()\n",
    "    candles['ewma_volume'] = candles['volume'].ewm(span=ewma_span).mean()\n",
    "\n",
    "    candles['macd'], candles['macd_signal'], candles['macd_hist'] = talib.MACD(\n",
    "        candles['close_price'].values, fastperiod=macd_fast, slowperiod=macd_slow)\n",
    "\n",
    "    for period in [5, 10, 20]:\n",
    "        candles[f'direction_{period}'] = np.sign(candles['close_price'].diff(period)).fillna(0).astype(int)\n",
    "        candles[f'sma_{period}'] = candles['close_price'].rolling(window=period).mean()\n",
    "        candles[f'above_sma_{period}'] = (candles['close_price'] > candles[f'sma_{period}']).astype(int)\n",
    "\n",
    "    sma_5 = candles['close_price'].rolling(window=5).mean()\n",
    "    for period in [10, 20]:\n",
    "        sma_period = candles['close_price'].rolling(window=period).mean()\n",
    "        candles[f'ma_crossover_{period}'] = ((sma_5 > sma_period) & (sma_5.shift(1) <= sma_period.shift(1))).astype(int)\n",
    "\n",
    "    candles['bb_upper'], candles['bb_middle'], candles['bb_lower'] = talib.BBANDS(\n",
    "        candles['close_price'].values, timeperiod=bbands_period)\n",
    "    candles['bb_width'] = (candles['bb_upper'] - candles['bb_lower']) / candles['bb_middle']\n",
    "    candles['bb_position'] = (candles['close_price'] - candles['bb_lower']) / (candles['bb_upper'] - candles['bb_lower'])\n",
    "    candles['atr_ratio'] = candles['atr'] / candles['close_price']\n",
    "\n",
    "    for fast, slow in [(12, 26), (5, 35)]:\n",
    "        macd, macd_signal, macd_hist = talib.MACD(candles['close_price'].values, fastperiod=fast, slowperiod=slow)\n",
    "        candles[f'macd_{fast}_{slow}'] = macd\n",
    "        candles[f'macd_signal_{fast}_{slow}'] = macd_signal\n",
    "        candles[f'macd_hist_{fast}_{slow}'] = macd_hist\n",
    "        candles[f'macd_cross_{fast}_{slow}'] = ((macd > macd_signal) & (np.roll(macd, 1) <= np.roll(macd_signal, 1))).astype(int)\n",
    "\n",
    "    candles['time_segment'] = pd.cut(candles['minute_of_day'], bins=[0, 360, 720, 1080, 1440], labels=['night', 'morning', 'afternoon', 'evening'])\n",
    "    for segment in ['night', 'morning', 'afternoon', 'evening']:\n",
    "        candles[f'time_{segment}'] = (candles['time_segment'] == segment).astype(int)\n",
    "\n",
    "    candles['obv_trend'] = candles['obv'] * candles['adx']\n",
    "    candles['volume_volatility'] = candles['volume_ratio'] * candles['rolling_volatility']\n",
    "    candles['time_volume'] = candles['minute_of_day'] * candles['volume_ratio']\n",
    "\n",
    "    candles.fillna(candles.mean(numeric_only=True), inplace=True)\n",
    "    return candles\n",
    "\n",
    "\n",
    "import joblib\n",
    "import time\n",
    "import os\n",
    "\n",
    "def load_latest_model(model_dir=\"/data/models\", retries=5, delay=1.0):\n",
    "    \"\"\"\n",
    "    Safely load the latest model pickle file, retrying if the file is being written.\n",
    "    \"\"\"\n",
    "    latest_path = os.path.join(model_dir, \"latest.pkl\")\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            model = joblib.load(latest_path)\n",
    "            return model\n",
    "        except (EOFError, FileNotFoundError, PermissionError) as e:\n",
    "            # File is being written or not yet available\n",
    "            print(f\"Attempt {attempt+1}: Model file not ready ({e}), retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "    raise RuntimeError(f\"Could not load model from {latest_path} after {retries} attempts.\")\n",
    "\n",
    "# Usage:\n",
    "# model = load_latest_model(\"/data/models\")\n",
    "\n",
    "# --- Prediction pipeline ---\n",
    "def predict_and_save():\n",
    "    duckdb_file = '/data/crypto.duckdb'\n",
    "    candles_table = 'candles'\n",
    "    predictions_table = 'predictions'\n",
    "    model_path = '/data/models/latest.pkl'\n",
    "    metrics_path = '/data/models/latest.json'\n",
    "\n",
    "    # 1. Load model and feature params\n",
    "    model = joblib.load(model_path)\n",
    "    with open(metrics_path, 'r') as f:\n",
    "        best_params = json.load(f)['best_params']\n",
    "\n",
    "    # 2. Fetch last 30 days of candles\n",
    "    now = datetime.utcnow()\n",
    "    start_time = now - timedelta(days=30)\n",
    "    query = f\"\"\"\n",
    "        SELECT * FROM {candles_table}\n",
    "        WHERE interval_start >= '{start_time.strftime('%Y-%m-%d %H:%M:%S')}'\n",
    "        ORDER BY interval_start\n",
    "    \"\"\"\n",
    "    with duckdb.connect(duckdb_file) as conn:\n",
    "        candles = conn.execute(query).fetchdf()\n",
    "\n",
    "    # 3. Feature columns (must match training)\n",
    "    feature_columns = [\n",
    "        'rsi', 'macd', 'macd_signal', 'macd_hist', 'adx', 'obv', 'obv_rolling', 'willr', 'mfi',\n",
    "        'trix', 'tema', 'dx', 'sar', 'atr', 'rolling_volatility', 'volume_spike',\n",
    "        'minute_of_day', 'momentum_5', 'momentum_15', 'range_ratio', 'slope_10',\n",
    "        'day_of_week', 'hour_sin', 'hour_cos', 'minutes_from_us_open',\n",
    "        'minutes_from_asia_open', 'minutes_from_europe_open', 'us_time_sin',\n",
    "        'us_time_cos', 'asia_time_sin', 'asia_time_cos', 'europe_time_sin',\n",
    "        'europe_time_cos', 'volume_ema', 'volume_ratio', 'volume_oscillator',\n",
    "        'vwap_ratio', 'adx_strong', 'direction_5', 'direction_10', 'direction_20',\n",
    "        'above_sma_5', 'above_sma_10', 'above_sma_20', 'bb_width', 'bb_position',\n",
    "        'atr_ratio', 'macd_12_26', 'macd_signal_12_26', 'macd_hist_12_26',\n",
    "        'macd_5_35', 'macd_signal_5_35', 'macd_hist_5_35', 'macd_cross_12_26',\n",
    "        'macd_cross_5_35', 'time_night', 'time_morning', 'time_afternoon',\n",
    "        'time_evening', 'obv_trend', 'volume_volatility', 'time_volume',\n",
    "        'ewma_close', 'ewma_volume'\n",
    "    ]\n",
    "\n",
    "    # 4. Generate features using best_params\n",
    "    feature_param_keys = [\n",
    "        'rolling_volatility_window', 'trix_period',\n",
    "        'tema_period', 'bbands_period', 'macd_fast', 'macd_slow', 'obv_window', 'ewma_span'\n",
    "    ]\n",
    "    feature_params = {k: best_params[k] for k in feature_param_keys}\n",
    "    candles = generate_features(candles, **feature_params, predict_horizon_minutes=5)\n",
    "\n",
    "    # 5. Predict for the most recent candle\n",
    "    latest_row = candles.iloc[[-1]]\n",
    "    X_latest = latest_row[feature_columns]\n",
    "    signal = int(model.predict(X_latest)[0])\n",
    "    proba = float(model.predict_proba(X_latest)[0][1])\n",
    "    interval_start = latest_row['interval_start'].iloc[0]\n",
    "    interval_end = latest_row['interval_end'].iloc[0]\n",
    "\n",
    "    # 6. Save prediction to DuckDB (create table if not exists)\n",
    "    with duckdb.connect(duckdb_file) as conn:\n",
    "        conn.execute(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS predictions (\n",
    "                interval_start TIMESTAMP,\n",
    "                interval_end TIMESTAMP,\n",
    "                signal INTEGER,\n",
    "                proba DOUBLE,\n",
    "                PRIMARY KEY (interval_start, interval_end)\n",
    "            )\n",
    "        \"\"\")\n",
    "        conn.execute(f\"\"\"  \n",
    "            INSERT INTO predictions (interval_start, interval_end, signal, proba)  \n",
    "            VALUES (?, ?, ?, ?)  \n",
    "            ON CONFLICT(interval_start, interval_end) DO UPDATE SET  \n",
    "                signal=excluded.signal,  \n",
    "                proba=excluded.proba  \n",
    "        \"\"\", [interval_start, interval_end, signal, proba])\n",
    "\n",
    "    print(f\"Prediction saved: {interval_start} | signal={signal} | proba={proba:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # * * * * * sleep 15; /usr/bin/python3 /path/to/predict.py\n",
    "    predict_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e4234b-410e-42c7-81f7-06684152a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect('/data/crypto.duckdb')\n",
    "conn.execute(\"DROP TABLE IF EXISTS predictions\")\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
